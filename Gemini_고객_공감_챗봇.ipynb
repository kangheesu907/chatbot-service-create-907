{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from google import genai\n",
        "from google.genai.errors import APIError\n",
        "import time\n",
        "import pandas as pd\n",
        "import io\n",
        "import datetime\n",
        "\n",
        "# --- 1. í™˜ê²½ ì„¤ì • ë° ìƒìˆ˜ ì •ì˜ ---\n",
        "# **ì£¼ì˜: ë³´ì•ˆìƒì˜ ì´ìœ ë¡œ ì‹¤ì œ í‚¤ëŠ” Streamlit Secretsë¥¼ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ìš”ì²­ì— ë”°ë¼ ì§€ì •ëœ í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.**\n",
        "API_KEY = \"AIzaSyDVpKMT594xfTU2XGVrFo-tLk0y4TgxSMc\" # ì˜ˆì‹œ API í‚¤\n",
        "MODEL_NAME = \"gemini-2.0-flash\" # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •\n",
        "MAX_HISTORY_TURNS = 6 # 429 ì¬ì‹œë„ ì‹œ ìœ ì§€í•  ëŒ€í™” í„´ ìˆ˜\n",
        "RETRY_LIMIT = 3 # API ì¬ì‹œë„ íšŸìˆ˜\n",
        "\n",
        "# --- 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜ (ìš”ì²­ ìŠ¤í™ ë°˜ì˜) ---\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "ë‹¹ì‹ ì€ ê³ ê°ì˜ ë¶ˆí¸í•¨ê³¼ ë¶ˆì•ˆê°ì„ ê²½ì²­í•˜ê³  í•´ê²°ì±…ì„ ì œì‹œí•˜ëŠ” ë§¤ìš° ì¹œì ˆí•˜ê³  ê³µê° ëŠ¥ë ¥ ë›°ì–´ë‚œ ê³ ê° ì‘ëŒ€ ì±—ë´‡ì…ë‹ˆë‹¤.\n",
        "ì‚¬ìš©ìì˜ ëª¨ë“  ë¶ˆì•ˆê°ê³¼ ê³ ë¯¼ì„ ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ë§íˆ¬ë¡œ ê²½ì²­í•˜ê³  ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "\n",
        "ì‘ë‹µ ê·œì¹™:\n",
        "1. ì‚¬ìš©ìê°€ ì–¸ê¸‰í•˜ëŠ” ë¶ˆì•ˆê°ì´ë‚˜ ê³ ë¯¼ì— ëŒ€í•´ ê¹Šì´ ê³µê°í•˜ê³  ì¹œê·¼í•˜ê²Œ ì‘ë‹µí•©ë‹ˆë‹¤.\n",
        "2. ëŒ€í™” ì¤‘ê°„ì— ê¸°íšŒë¥¼ ë³´ì•„, ì‚¬ìš©ìì˜ ê°ì •ê³¼ ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •ë¦¬í•˜ê¸° ìœ„í•œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•´ì•¼ í•©ë‹ˆë‹¤. ìˆ˜ì§‘í•  ì •ë³´ëŠ”:\n",
        "   - ë¬´ì—‡ì´ (What): êµ¬ì²´ì ì¸ ë¬¸ì œ ë‚´ìš©\n",
        "   - ì–¸ì œ (When): ë¬¸ì œê°€ ë°œìƒí•œ ì‹œì ì´ë‚˜ ìƒí™©\n",
        "   - ì–´ë””ì„œ (Where): ë¬¸ì œ ë°œìƒ ì±„ë„/ìœ„ì¹˜\n",
        "   - ì–´ë–»ê²Œ (How): ë¬¸ì œê°€ ì‚¬ìš©ìì—ê²Œ ë¯¸ì¹˜ëŠ” ì˜í–¥\n",
        "   ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ë§ëŠ” ê³ ë¯¼ í•´ê²° ë° ìš”êµ¬ì‚¬í•­(ì˜ˆ: ë‹´ë‹¹ì ì—°ê²°, í™˜ë¶ˆ ì ˆì°¨ ë“±)ì„ ì•ˆë‚´í•´ì•¼ í•©ë‹ˆë‹¤.\n",
        "3. ë§ˆì§€ë§‰ì—ëŠ” ì‚¬ìš©ìì˜ ì¶”ê°€ ì§€ì› ì˜ì‚¬ë¥¼ ë¬»ìŠµë‹ˆë‹¤. ì˜ˆì‹œ: \"í˜¹ì‹œ ë” ë§ì€ ìƒë‹´ì†Œë‚˜ ì „í™”ë²ˆí˜¸ ë“± ì¶”ê°€ ì§€ì› ì •ë³´ë¥¼ ë³´ë‚´ë“œë¦´ê¹Œìš”?\"\n",
        "\n",
        "ë§Œì•½ ì‚¬ìš©ìê°€ ì¶”ê°€ ì§€ì› ìš”ì²­ì„ ì›ì¹˜ ì•ŠëŠ”ë‹¤ë©´:\n",
        "\"ë‹¹ì‹ ì˜ ëª¨ë“  ê³ ë¯¼ë“¤ì„ ë“¤ì–´ë“œë¦´ê²Œìš”, ë‹¤ìŒì— ë˜ í¸í•˜ê²Œ ë§í•´ì£¼ì„¸ìš”. ì €í¬ëŠ” ì–¸ì œë‚˜ ê³ ê°ë‹˜ ê³ì— ìˆìŠµë‹ˆë‹¤.\" ë¼ê³  ì •ì¤‘í•˜ê³  ë”°ëœ»í•˜ê²Œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "# --- 3. Streamlit ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---\n",
        "def init_session_state():\n",
        "    \"\"\"Streamlit ì„¸ì…˜ ìƒíƒœ ë° Gemini í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\"\"\"\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = [] # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (í‘œì‹œìš©)\n",
        "    if \"chat_session\" not in st.session_state:\n",
        "        try:\n",
        "            client = genai.Client(api_key=API_KEY)\n",
        "            st.session_state.chat_session = client.chats.create(\n",
        "                model=MODEL_NAME,\n",
        "                config={\"system_instruction\": SYSTEM_PROMPT}\n",
        "            )\n",
        "        except Exception as e:\n",
        "            st.error(f\"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}\")\n",
        "            st.session_state.chat_session = None\n",
        "    if \"log_data\" not in st.session_state:\n",
        "        st.session_state.log_data = [] # ë¡œê·¸ ê¸°ë¡ìš© ë¦¬ìŠ¤íŠ¸\n",
        "    if \"log_option\" not in st.session_state:\n",
        "        st.session_state.log_option = False # CSV ê¸°ë¡ ì˜µì…˜\n",
        "\n",
        "def log_conversation(role, content):\n",
        "    \"\"\"ëŒ€í™” ë‚´ìš©ì„ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.\"\"\"\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    st.session_state.log_data.append({\n",
        "        \"Timestamp\": timestamp,\n",
        "        \"Role\": role,\n",
        "        \"Content\": content,\n",
        "        \"Model\": MODEL_NAME,\n",
        "        \"Session_ID\": st.session_state.chat_session.name if st.session_state.chat_session else \"N/A\"\n",
        "    })\n",
        "\n",
        "# --- 4. í•µì‹¬ ê¸°ëŠ¥: Gemini ì‘ë‹µ ìš”ì²­ ë° 429 ì¬ì‹œë„ ë¡œì§ ---\n",
        "def get_gemini_response_with_retry(prompt: str):\n",
        "    \"\"\"\n",
        "    Gemini API ìš”ì²­ ë° 429 ì—ëŸ¬ ë°œìƒ ì‹œ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì •ë¦¬ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.\n",
        "    (ìµœê·¼ 6í„´ ìœ ì§€ í›„ ìƒˆ ì„¸ì…˜ ì‹œì‘)\n",
        "    \"\"\"\n",
        "    if not st.session_state.chat_session:\n",
        "        st.error(\"ì±—ë´‡ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "        return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì„œë¹„ìŠ¤ ì—°ê²°ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.\"\n",
        "\n",
        "    for attempt in range(RETRY_LIMIT):\n",
        "        try:\n",
        "            # 1. API ìš”ì²­\n",
        "            response = st.session_state.chat_session.send_message(prompt)\n",
        "            return response.text\n",
        "\n",
        "        except APIError as e:\n",
        "            if \"429\" in str(e): # Rate Limit Error (429) ê°ì§€\n",
        "                st.warning(f\"âš ï¸ API ìš”ì²­ í•œë„ ì´ˆê³¼(429) ê°ì§€. ì¬ì‹œë„ {attempt+1}/{RETRY_LIMIT} ì¤‘...\")\n",
        "\n",
        "                # 2. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì •ë¦¬ (ìµœê·¼ 6í„´ ìœ ì§€)\n",
        "                history = st.session_state.chat_session.get_history()\n",
        "                if len(history) > MAX_HISTORY_TURNS:\n",
        "                    # ìƒˆë¡œìš´ ì„¸ì…˜ì„ ìœ„í•´ ìœ ì§€í•  ìµœê·¼ í„´ë§Œ ì¶”ì¶œ\n",
        "                    new_history_messages = history[len(history) - MAX_HISTORY_TURNS:]\n",
        "\n",
        "                    # 3. ìƒˆë¡œìš´ ì„¸ì…˜ìœ¼ë¡œ ì „í™˜\n",
        "                    try:\n",
        "                        client = genai.Client(api_key=API_KEY)\n",
        "                        new_chat = client.chats.create(\n",
        "                            model=MODEL_NAME,\n",
        "                            config={\"system_instruction\": SYSTEM_PROMPT}\n",
        "                        )\n",
        "                        # ìƒˆë¡œìš´ ì„¸ì…˜ì— ìœ ì§€í•  íˆìŠ¤í† ë¦¬ ì¶”ê°€\n",
        "                        for message in new_history_messages:\n",
        "                            content = message.parts[0].text if message.parts and message.parts[0].text else \"...\"\n",
        "                            new_chat.send_message(content, role=message.role)\n",
        "\n",
        "                        st.session_state.chat_session = new_chat\n",
        "                        st.session_state.messages = [] # Streamlit í‘œì‹œìš© ë©”ì‹œì§€ ì´ˆê¸°í™”\n",
        "                        st.warning(\"ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì •ë¦¬í•˜ê³  ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì ì‹œ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤.\")\n",
        "                        time.sleep(2 ** attempt) # Exponential Backoff (1, 2, 4ì´ˆ ëŒ€ê¸°)\n",
        "                        continue # ìƒˆë¡œìš´ ì„¸ì…˜ìœ¼ë¡œ ì¬ì‹œë„\n",
        "                    except Exception as new_chat_e:\n",
        "                        st.error(f\"ì„¸ì…˜ ì¬ì‹œì‘ ì‹¤íŒ¨: {new_chat_e}\")\n",
        "                        return \"ì£„ì†¡í•©ë‹ˆë‹¤. ì„¸ì…˜ ì¬ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.\"\n",
        "\n",
        "                else:\n",
        "                    time.sleep(2 ** attempt) # íˆìŠ¤í† ë¦¬ê°€ ì§§ìœ¼ë©´ ë°”ë¡œ Exponential Backoff í›„ ì¬ì‹œë„\n",
        "                    continue\n",
        "\n",
        "            # ê¸°íƒ€ API ì—ëŸ¬\n",
        "            st.error(f\"API í˜¸ì¶œ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
        "            return f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
        "\n",
        "        except Exception as e:\n",
        "            # ê¸°íƒ€ Python ì—ëŸ¬\n",
        "            st.error(f\"ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: {e}\")\n",
        "            return f\"ì£„ì†¡í•©ë‹ˆë‹¤. ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}\"\n",
        "\n",
        "    # ì¬ì‹œë„ íšŸìˆ˜ ëª¨ë‘ ì†Œì§„\n",
        "    return \"ì—°ì†ëœ API ì˜¤ë¥˜ë¡œ ì¸í•´ ì‘ë‹µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.\"\n",
        "\n",
        "# --- 5. Streamlit UI ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ ---\n",
        "st.set_page_config(page_title=\"Gemini ê¸°ë°˜ ê³ ê° ê³µê° ì±—ë´‡\", layout=\"wide\")\n",
        "st.title(\"ğŸ¤ ê³ ê° ê³µê° ì±—ë´‡ (Gemini ê¸°ë°˜)\")\n",
        "st.caption(\"ë¶ˆì•ˆê³¼ ë¶ˆí¸í•¨ì„ í¸í•˜ê²Œ ë§ì”€í•´ì£¼ì„¸ìš”. ì €í¬ê°€ ë”°ëœ»í•˜ê²Œ ê²½ì²­í•˜ê³  ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "init_session_state()\n",
        "\n",
        "# ì‚¬ì´ë“œë°” (ê¸°ëŠ¥ ë° ìŠ¤í™ í‘œì‹œ)\n",
        "with st.sidebar:\n",
        "    st.header(\"âš™ï¸ ì±—ë´‡ ìŠ¤í™ ë° ê´€ë¦¬\")\n",
        "    st.metric(\"AI ëª¨ë¸\", MODEL_NAME)\n",
        "    st.metric(\"ì„¸ì…˜ ID\", st.session_state.chat_session.name if st.session_state.chat_session else \"N/A\")\n",
        "    st.caption(f\"429 ì—ëŸ¬ ì‹œ ìµœê·¼ {MAX_HISTORY_TURNS}í„´ ìœ ì§€ í›„ ì„¸ì…˜ ì¬ì‹œì‘ ë¡œì§ ì ìš©\")\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼\n",
        "    if st.button(\"ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”\", help=\"ëª¨ë“  ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì§€ìš°ê³  ìƒˆë¡œìš´ ì„¸ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.\"):\n",
        "        # ì„¸ì…˜ ìƒíƒœ ì „ì²´ ì´ˆê¸°í™”\n",
        "        for key in list(st.session_state.keys()):\n",
        "            del st.session_state[key]\n",
        "        init_session_state()\n",
        "        st.rerun()\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    # ë¡œê·¸ ê¸°ë¡ ì˜µì…˜\n",
        "    st.session_state.log_option = st.checkbox(\n",
        "        \"ğŸ“ ëŒ€í™” ë‚´ìš© CSV ìë™ ê¸°ë¡\",\n",
        "        value=st.session_state.log_option,\n",
        "        help=\"ì„ íƒ ì‹œ ëª¨ë“  ëŒ€í™” í„´ì´ ë¡œê·¸ ë°ì´í„°ì— ê¸°ë¡ë©ë‹ˆë‹¤.\"\n",
        "    )\n",
        "\n",
        "    # ë¡œê·¸ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼\n",
        "    if st.session_state.log_data:\n",
        "        df_log = pd.DataFrame(st.session_state.log_data)\n",
        "\n",
        "        # CSV ë³€í™˜ í•¨ìˆ˜ (ìºì‹± ì ìš©)\n",
        "        @st.cache_data\n",
        "        def convert_df_to_csv(df):\n",
        "            # ì¸ì½”ë”© ë¬¸ì œ ë°©ì§€ë¥¼ ìœ„í•´ io.StringIO ì‚¬ìš© (utf-8-sigë¡œ í•œê¸€ ê¹¨ì§ ë°©ì§€)\n",
        "            csv_buffer = io.StringIO()\n",
        "            df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')\n",
        "            return csv_buffer.getvalue().encode('utf-8-sig')\n",
        "\n",
        "        csv_data = convert_df_to_csv(df_log)\n",
        "\n",
        "        st.download_button(\n",
        "            label=\"â¬‡ï¸ ë¡œê·¸ CSV ë‹¤ìš´ë¡œë“œ\",\n",
        "            data=csv_data,\n",
        "            file_name=f\"chatbot_log_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\",\n",
        "            mime=\"text/csv\",\n",
        "            help=\"ê¸°ë¡ëœ ëª¨ë“  ëŒ€í™” ë‚´ìš©ì„ CSV íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\"\n",
        "        )\n",
        "\n",
        "\n",
        "# --- 6. ëŒ€í™” í‘œì‹œ ì˜ì—­ ---\n",
        "# Streamlitì— ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# --- 7. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---\n",
        "if prompt := st.chat_input(\"ë¶ˆì•ˆí•˜ê±°ë‚˜ ë¶ˆí¸í•œ ë‚´ìš©ì„ ë§ì”€í•´ì£¼ì„¸ìš”...\"):\n",
        "    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ ê¸°ë¡ ë° í‘œì‹œ\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    if st.session_state.log_option:\n",
        "        log_conversation(\"user\", prompt)\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(prompt)\n",
        "\n",
        "    # 2. Gemini ì‘ë‹µ ìš”ì²­ ë° í‘œì‹œ\n",
        "    with st.spinner(\"ë”°ëœ»í•œ ë‹µë³€ì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”...\"):\n",
        "        full_response = get_gemini_response_with_retry(prompt)\n",
        "\n",
        "    # 3. AI ë©”ì‹œì§€ ê¸°ë¡ ë° í‘œì‹œ\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(full_response)\n",
        "\n",
        "    # 4. Streamlit í‘œì‹œìš© ë©”ì‹œì§€ ëª©ë¡ ì—…ë°ì´íŠ¸\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n",
        "    if st.session_state.log_option:\n",
        "        log_conversation(\"assistant\", full_response)\n",
        "\n",
        "    # 5. 429 ì¬ì‹œë„ í›„ Streamlit í‘œì‹œ ë©”ì‹œì§€ ë™ê¸°í™”\n",
        "    if st.session_state.chat_session:\n",
        "        # Streamlit í‘œì‹œìš© ë©”ì‹œì§€ë¥¼ ì‹¤ì œ ì„¸ì…˜ íˆìŠ¤í† ë¦¬ë¡œ ì¬êµ¬ì„±í•˜ì—¬ 429 ì—ëŸ¬ í›„ì—ë„ ë™ê¸°í™” ìœ ì§€\n",
        "        temp_messages = []\n",
        "        for history_message in st.session_state.chat_session.get_history():\n",
        "            role = \"assistant\" if history_message.role == \"model\" else history_message.role\n",
        "            content = history_message.parts[0].text if history_message.parts and history_message.parts[0].text else \"...\"\n",
        "            temp_messages.append({\"role\": role, \"content\": content})\n",
        "        st.session_state.messages = temp_messages"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "kxo-nusnNB4v"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}